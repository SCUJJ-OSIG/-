---
x
author: 创新实验室
date: 2023-11-12
github仓库: https://github.com/SCUJJ-OSIG/knowledge_base
Description: 虚拟机
---




#  前景

已经完成haodop的克隆如下：

![image-20231103150330388](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/image-20231103150330388.png)



## 1.1编写集群分发脚本 xsync

### **1.1.1xsync集群分发脚本**

 ①在用的家目录/home/atguigu下创建bin文件夹

```
atguigu@hadoop102 ~]$ mkdir bin
```

②在/home/atguigu/bin目录下创建xsync文件，以便全局调用

```
[atguigu@hadoop102 ~]$ cd /home/atguigu/bin
[atguigu@hadoop102 ~]$ vim xsync

```

在该文件中编写如下代码

```
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
  echo Not Enough Arguement!
  exit;
fi
#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
  echo ====================  $host  ====================
  #3. 遍历所有目录，挨个发送
  for file in $@
  do
    #4 判断文件是否存在
    if [ -e $file ]
    then
      #5. 获取父目录
      pdir=$(cd -P $(dirname $file); pwd)
      #6. 获取当前文件的名称
      fname=$(basename $file)
      ssh $host "mkdir -p $pdir"
      rsync -av $pdir/$fname $host:$pdir
    else
      echo $file does not exists!
    fi
  done
done

```



>
>
>这个xsync配置好之后还要copy到系统的环境变量
>
>```bash
>bash: xsync: command not found的解决方法
>
>
>   #自己在用户目录下，编写的/bin文件没有拷贝到系统目录的bin下。  个人用户的bin，不在path中，拷贝过去后才能过去个人用户的环境变量。
>#解决方法：
>  #将自己编写的/bin文件拷贝到系统目录的bin下
>sudo cp xsync /bin
>```
>
>



>**vscode** 直接进入xsync文件，粘贴如下
>
>

![image-20231103153701932](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/image-20231103153701932.png)

##  1.2 SSH无密登录配置

说明：这里面只配置了hadoop102、hadoop103到其他主机的无密登录；因为hadoop102未外配置的是NameNode，hadoop103配置的是ResourceManager，都要求对其他节点无密访问。

（1）hadoop102上生成公钥和私钥：

```
[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa
```

然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）

（2）将hadoop102公钥拷贝到要免密登录的目标机器上

```
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104

```

（3）hadoop103上生成公钥和私钥：

```
[atguigu@hadoop103 .ssh]$ ssh-keygen -t rsa
```

然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）

（4）将hadoop103公钥拷贝到要免密登录的目标机器上

```
[atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop102
[atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop103
[atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop104

```





>
>
>**vscode** 会有一个弹出
>
>如下图

![image-20231103154052059](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/image-20231103154052059.png)

![image-20231103154408565](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/image-20231103154408565.png)

## 1.3 SDK安装

### 1.3.1 卸载现有JDK（3台节点）

```bash
[atguigu@hadoop102 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps
[atguigu@hadoop103 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps

[atguigu@hadoop104 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps
```

​    （1）rpm -qa：表示查询所有已经安装的软件包

​    （2）grep -i：表示过滤时不区分大小写

​    （3）xargs -n1：表示一次获取上次执行结果的一个值

​    （4）rpm -e --nodeps：表示卸载软件

###  1.3.2**将JDK**导入到hadop102的/opt/software文件夹下面

直接用vscode界面，把安装包拖入文件夹下面

![image-20231103160543072](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/image-20231103160543072.png)



注:请拖到对应文件下，不然你拖不进去。

![image-20231103160821537](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/image-20231103160821537.png)

### 1.3.3 **解压JDK**到/opt/module目录下

ctrl +shift+~ 召唤命令行，进入software目录，



```bash
[atguigu@hadoop102 opt]# cd  software
[atguigu@hadoop102 software]# tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
$ cd /opt/module/
[atguigu@hadoop102 module]$ mv jdk1.8.0_212/ jdk 

```

### 1.3.4  **配置JDK环境变量**



（1）新建/etc/profile.d/my_env.sh文件

```
[atguigu@hadoop102 module]# sudo vim /etc/profile.d/my_env.sh
```



添加如下内容，然后保存（:wq）退出

```
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk
export PATH=$PATH:$JAVA_HOME/bin

```

>**加上sudo即可，权限就有了**
>
>粘贴到vscode的命令行的命令可能丢失；#号注释的都会丢失。
>
>所以该补全的补全
>
>如果已经弄错了，想要删掉这个配置文件，rm时会提示，少了权限。
>
>少权限，只能登录root用户，去这个配置文件夹，修改权限
>
>my_env.sh

```
[atguigu@hadoop102 software] cd /etc/profile.d/
[atguigu@hadoop102 software] ll #可以看下权限都是root
[atguigu@hadoop102 software] chown atguigu:atguigu my_env.sh 
#这个时候vscode里面可以删了
```

![image-20231103164423246](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/image-20231103164423246.png)

（2）让环境变量生效

```
[atguigu@hadoop102 software]$ source /etc/profile.d/my_env.sh
```

###  **1.3.5**   测试JDK是否安装成功

```
[atguigu@hadoop102 module]# java -version
```

```
如果能看到以下结果、则Java正常安装
java version "1.8.0_212"

```

### 1.3.6 **分发JDK**

```
[atguigu@hadoop102 module]$ xsync /opt/module/jdk
```



### 1.3.7 **分发环境变量配置文件**

```bash
[atguigu@hadoop102 module]$ sudo /home/atguigu/bin/xsync /etc/profile.d/my_env.sh
```



### 1.3.8 **分别在hadoop103、hadoop104上执行source**

```
[atguigu@hadoop103 module]$ source /etc/profile.d/my_env.sh
[atguigu@hadoop104 module]$ source /etc/profile.d/my_env.sh

```

## 1.3.5 环境变量配置说明

Linux的环境变量可在多个文件中配置，如/etc/profile，/etc/profile.d/*.sh，~/.bashrc，~/.bash_profile等，下面说明上述几个文件之间的关系和区别。

bash的运行模式可分为login shell和non-login shell。

例如，我们通过终端，输入用户名、密码，登录系统之后，得到就是一个login shell。而当我们执行以下命令ssh hadoop103 command，在hadoop103执行command的就是一个non-login shell。![image-20231103164857337](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/image-20231103164857337.png)



这两种shell的主要区别在于，它们启动时会加载不同的配置文件，login shell启动时会加载/etc/profile，~/.bash_profile，~/.bashrc。non-login shell启动时会加载~/.bashrc。

而在加载~/.bashrc（实际是~/.bashrc中加载的/etc/bashrc）或/etc/profile时，都会执行如下代码片段，

![image-20231103164921565](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/image-20231103164921565.png)

因此不管是login shell还是non-login shell，启动时都会加载/etc/profile.d/*.sh中的环境变量。





error： [CentOS7 yum提示:](https://blog.csdn.net/u011781521/article/details/52950254)

```bash

another app is currently holding the yum lock;waiting for it to exit


#解决
rm -f /var/run/yum.pid
#查看是否有yum进程
ps aux|grep yum

```







## 1.6 群起集群

**1**  **启动集群**

​    （1）**如果集群是第一次启动**，需要在hadoop102节点格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）

````bash
[atguigu@hadoop102 hadoop]$ bin/hdfs namenode -format

````

>
>
>可能的错误
>
>

```bash
#1.没有那个文件或目录
-bash: bin/hdfs: 没有那个文件或目录

#解决： sudo  bin/hdfs namenode -format

#2. JAVA_HOME is not set and could not be found


   #首先确定JDK是否安装配置：通过 java -version查看JDK版本信息

   #如果查询不到版本信息，参考JDK安装配置

   #在JDK配置无错的情况下，可能是没有配置hadoop-env.sh文件。这个文件里写的是hadoop的环境变量,主要修改hadoop的JAVA_HOME路径。

   #切到 [hadoop]/etc/hadoop目录

vim hadoop-env.sh
   #修改java_home路径和hadoop_conf_dir路径为具体的安装路径

export JAVA_HOME=/usr/jdk1.8.0_65
export HADOOP_CONF_DIR=/usr/hadoop-3.1.3/etc/hadoop


   #重新加载使修改生效：
source hadoop-env.sh


```





（2）启动HDFS

```bash
[atguigu@hadoop102 hadoop]$ sbin/start-dfs.sh
```

> 报错

```bash

#sbin/start-dfs.sh
Starting namenodes on [hadoop100]
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
Starting datanodes
ERROR: Attempting to operate on hdfs datanode as root
ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.

#解决

ERROR: Attempting to operate on yarn resourcemanager as root
ERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.

   #  出现以上报错信息需要到 sbin 目录下 更改 start-yarn.sh 和 stop-yarn.sh 信息，在两个配置文件的第一行添加：
   
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root

#最后再 输入命令 /sbin/start-yarn.sh 启动 yarn



```



```bash

[root@localhost sbin]# start-all.sh
Starting namenodes on [hadoop]
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
Starting datanodes
ERROR: Attempting to operate on hdfs datanode as root
ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.
Starting secondary namenodes [hadoop]
ERROR: Attempting to operate on hdfs secondarynamenode as root
ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.
2018-07-16 05:45:04,628 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting resourcemanager
ERROR: Attempting to operate on yarn resourcemanager as root
ERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.
Starting nodemanagers
ERROR: Attempting to operate on yarn nodemanager as root
ERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation.


#解决办法

```

[解决办法](https://blog.csdn.net/weixin_49736959/article/details/108897129)





## *Vim查找命令及快捷键*

### 一、通过指令查找

1.左斜杠/ 　从光标所在位置向文件尾搜索



```bash
／hello
```




2、问号？　从光标所在位置向文件头搜索

```
?hello
```

注：／和？均可加参数做指定查找（两者搜索方向不同，此处以／举例进行说明）

3.<匹配单词的开头　\>匹配单词的结尾



```
< hel 可以找到所有以hel开头的单词 （此处为了编辑方便我在<和hel中加了空格，实际不应有此空格）
　　 　　 \>llo 可以找到所有以llo结尾的单词
　　 　　 < for>可以找到所有的for单词，forever中的for不会被找到 （此处为了编辑方便我在<和for中加了空格，实际
　　 　　 　　　不应有此空格）

```



4. ＾代表行首　＄代表行尾

   ```
   
   ＾hello 只会匹配行首的hello
   　　　　 $hello 只会匹配行尾的hello
   ```

4.　

```
　　
　　　　
另：按"n"或者“N”可对找到的词进行后一个或者前一个的跳转

二、通过快捷键查找

　1、#　开始向文件头的方向搜索光标所在位置的单词的下一个出现位置
　2、*　开始向文件尾的方向搜索光标所在位置的单词的下一个出现位置

另：被查找到的单词会高亮显示，如想要去除该高亮显示，可使用命令 ：nohl （即no high light的意思）











```

> 报错



（3）**在配置了**  **ResourceManager** **的节点（hadoop103** **）**启动YARN

```bash
[atguigu@hadoop103 hadoop]$ sbin/start-yarn.sh
```

（4）Web端查看HDFS的Web页面：http://hadoop102:9870/

![img](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/clip_image002.jpg)

（5）Web端查看SecondaryNameNode

（a）浏览器中输入：http://hadoop104:9868/status.html

​        （b）查看SecondaryNameNode信息

![img](./%E8%99%9A%E6%8B%9F%E6%9C%BA.assets/clip_image004.jpg)





